---
title: "MSDS 6372 Project 2"
output: 
    html_document:
      keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(dplyr)
library(plyr)
library(glmnet)
library(ISLR)
library(leaps)
library(ggplot2)
library(ROCR)
library(MASS)
library(pheatmap)
library(randomForest)

load.libraries <- c('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'ggplot2', 'e1071', 'dplyr')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependences = TRUE)
sapply(load.libraries, require, character = TRUE)
```
##Data Set 1: Osteoporosis in Women

From Hosmer, Lemeshow, and Sturdivant (2013), Applied Logistic Regression, 3rd Edition.
The Global Longitudinal Study of Osteoporosis in Women (GLOW) is an international study of osteoporosis in women aged 55 years and over. The major goals of the study are to examine prevention and treatment of fractures and distribution of risk factors among older women. Complete details on the study as well as a list of GLOW publications may be found at the Center for Outcomes Research web site, <http://www.outcomes-umassmed.org/glow>. 
There are over 60K observations in the original data set. This data set contains a sample of 500 of them. 
The link below is to a website with the data set and description of the variables. The data set in question is called "glow500".

<https://www.umass.edu/statdata/statdata/data/glow/index.html>
Note: If you choose this data set, you MAY NOT use the Hosmer, Lemeshow, and Sturdivant text to help you in your analysis.
You may only use Chapter 1 in order to obtain a description of the data.

Of course if you dont have the book

<https://www.umass.edu/statdata/statdata/data/glow/glow.pdf>
provides definitions to the variables.


The Global Longitudinal Study of Osteoporosis in Women (GLOW) (2005-2014) was a prospective cohort study of physician practices in the provision of prophylaxis and treatment against osteoporotic fractures. The goal of this research was to improve understanding of the risk and prevention of osteoporosis-related fractures among female residents of 10 countries who were 55 years of age and older. GLOW enrolled over 60,000 women through over 700 physicians in 10 countries, and conducted annual follow-up for up to 5 years through annual patient questionnaires.

## Setup: Data Import and Cleaning

```{r}

dataset <- read.csv("C:/Users/carol/OneDrive/Documents/MSDS6372/Proj2/glow500.csv", sep=",", stringsAsFactors = TRUE, header=TRUE)

# List rows of data that have missing values 
Missing_values <- dataset[!complete.cases(dataset),]
# Create new dataset without missing data 
dataset <- na.omit(dataset)

#remove FRACSCORE feature per professor Turner
drops <- c("FRACSCORE")
dataset <- dataset[ , !(names(dataset) %in% drops)]

#Rename columns
colnames(dataset)[colnames(dataset)=="Ã¯..SUB_ID"] <- "SUB_ID"
View(dataset)
```
## Grouping Variables as Continuous, Categorical, and ID
```{r}
cont_var <- dataset[,5:8]
categoricalvar <- dataset[ ,-c(4,9:13)]
ID_var <- dataset[,c(1:3)]
```

##Create a vector of all categorical variables
```{r}
library(gmodels)
library(vcd)
categoricalvarvec  <- c("PRIORFRAC","PREMENO","MOMFRAC","ARMASSIST","SMOKE","RATERISK")
for(categoricalvar in categoricalvarvec){ 
  CrossTable(dataset[ , categoricalvar], dataset$FRACTURE, chisq = T) 
  mosaicplot(CrossTable(dataset[ ,categoricalvar], dataset$FRACTURE)$t, main=paste("FRACTURE vs",categoricalvar, setp=" "), xlab=categoricalvar, ylab= "FRACTURE", color=T)
}
```
## Setup: Train / Test
### Training set will be 70% of dataset and Test set will be remaining 30%
```{r include=FALSE}

smp_size <- floor(0.70 * nrow(cont_var))
set.seed(1234)
train_ind <-sample(seq_len(nrow(cont_var)), size=smp_size)
test <-cont_var[-train_ind,]
train <-cont_var[train_ind,]

```

##  Exploratory Data Analysis
### Summary Tables
```{r}

sapply(dataset, class)
dim(dataset)


attach(cont_var)

#Summary of Raw Dataset Continuous variables
train_ind <-which(sapply(cont_var,is.numeric))
tab.cont<-c()

for (i in train_ind){
  tab.cont<-rbind(tab.cont,summary(cont_var[,i]))
}
rownames(tab.cont)<-names(cont_var)[train_ind]
View(tab.cont)
tab.cont


index<-which(sapply(cont_var,is.numeric))
tab.cont<-c()

for (i in train_ind){
  tab.cont <-rbind(tab.cont,summary(cont_var[,i]))
}
rownames(tab.cont)<-names(cont_var)[train_ind]
View(tab.cont)
tab.cont
attach(cont_var)

#Summary of Train data Continuous variables
train_ind <-which(sapply(train,is.numeric))
tab.cont.train<-c()

for (i in train_ind){
  tab.cont.train<-rbind(tab.cont.train,summary(train[,i]))
}
rownames(tab.cont.train)<-names(train)[train_ind]
View(tab.cont.train)
tab.cont.train


index<-which(sapply(train,is.numeric))
tab.cont.train<-c()

for (i in train_ind){
  tab.cont.train <-rbind(tab.cont.train,summary(train[,i]))
}
rownames(tab.cont.train)<-names(train)[train_ind]
View(tab.cont.train)
tab.cont.train

#Summary of Test data Continuous variables
train_ind <-which(sapply(test,is.numeric))
tab.cont.test<-c()

for (i in train_ind){
  tab.cont.test<-rbind(tab.cont.test,summary(test[,i]))
}
rownames(tab.cont.test)<-names(test)[train_ind]
View(tab.cont.test)
tab.cont.test


index<-which(sapply(test,is.numeric))
tab.cont.test<-c()

for (i in train_ind){
  tab.cont.test <-rbind(tab.cont.test,summary(test[,i]))
}
rownames(tab.cont.test)<-names(test)[train_ind]
View(tab.cont.test)
tab.cont.test

 
#Sanity check make sure it is spilt roughly 50/50 in categorical and continous variables
prop.table(table(dataset$PRIORFRAC))
prop.table(table(dataset$PREMENO))
prop.table(table(dataset$ARMASSIST))
prop.table(table(dataset$SMOKE))
prop.table(table(dataset$MOMFRAC))

prop.table(table(dataset$AGE))
prop.table(table(dataset$BMI))
prop.table(table(dataset$HEIGHT))
prop.table(table(dataset$WEIGHT))


#Frequency tables

count(dataset,'AGE')
count(dataset,'BMI')
count(dataset,'HEIGHT')
count(dataset,'WEIGHT')
count(dataset,'PRIORFRAC')
count(dataset,'PREMENO')
count(dataset,'MOMFRAC')
count(dataset,'SMOKE')
count(dataset,'RATERISK')

```
###Correlation
# Use correlation plots to see which continuous variables are
# highly correlated and need to be focused on

```{r}
#Correlation
cor.mat <-cor(dataset[,index])
cor.mat

#These are the correlations of each predictor to FRACTURE
attach(dataset)
sort(cor.mat[11,])
plot(PRIORFRAC,FRACTURE)
plot(AGE,FRACTURE)
plot(WEIGHT,FRACTURE)
plot(HEIGHT,FRACTURE)
plot(BMI,FRACTURE)
plot(PREMENO,FRACTURE)
plot(MOMFRAC,FRACTURE)
plot(ARMASSIST,FRACTURE)
plot(SMOKE,FRACTURE)
plot(RATERISK,FRACTURE)

Numeric_Vars <- dataset[,sapply(dataset, is.integer)]

colnames(Numeric_Vars)

library("corrplot")

corrplot(cor(Numeric_Vars), method = "number", type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)



library(gridExtra)
theme_set(theme_light())


WEIGHT <- ggplot(dataset, aes(x = FRACTURE, y = WEIGHT)) +
               geom_boxplot() + coord_flip()

HEIGHT <- ggplot(dataset, aes(x = FRACTURE, y = HEIGHT)) +
               geom_boxplot() + coord_flip()

BMI <- ggplot(dataset, aes(x = FRACTURE, y = BMI)) +
                    geom_boxplot() + coord_flip()

AGE <- ggplot(dataset, aes(x = FRACTURE, y = AGE)) +
       geom_boxplot() + coord_flip()

grid.arrange(WEIGHT,
             HEIGHT, BMI,
             AGE,
             nrow = 3)
attach(dataset)

#Correlation plots
pairs(dataset[,1:11])
par(mfrow=c(1,3))
plot(dataset$WEIGHT,dataset$HEIGHT)
plot(dataset$AGE,dataset$PRIORFRAC)
plot(dataset$BMI,dataset$PREMENO)
plot(dataset$SMOKE,dataset$RATERISK)
plot(dataset$FRACTURE,dataset$RATERISK)

#Plotting data via ggplot2
mysummary <-function(x){
  result<-c(length(x),mean(x),sd(x),sd(x)/length(x))
  names(result)<-c("N","Mean","SD","SE")
  return(result)
}
sumstats<-aggregate(FRACTURE~RATERISK + PRIORFRAC,data=dataset,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
attach(sumstats)

ggplot(sumstats,aes(x=sumstats$PRIORFRAC,y=Mean,group=RATERISK,colour=RATERISK)) + ylab("Osteo Score") + geom_line() + geom_point() + xlab("Prior Fracture") +  geom_errorbar(aes(ymin=sumstats$Mean-sumstats$SE,ymax=sumstats$Mean+sumstats$SE),width=.1)


detach(dataset)
```
##PCA

```{r}
##glmnet
dat <- dataset
#Get Training Set
dat.train <- train

dat.train.x <- dat.train[,1:ncol(dat.train)]
dat.train.y <- dat.train$FRACTURE

dat.train.y <- as.factor(as.character(dat.train.y))

#PCA
pc.result<-prcomp(dat.train.x,scale.=TRUE)
pc.scores<-pc.result$x
pc.scores<-data.frame(pc.scores)
pc.scores$FRACTURE<-dat.train.y

PCA <- pc.result$rotation
PCA


#Scree plot
pc.eigen<-(pc.result$sdev)^2
pc.prop<-pc.eigen/sum(pc.eigen)
pc.cumprop<-cumsum(pc.prop)
plot(1:11,pc.prop,type="l",main="Scree Plot",ylim=c(0,1),xlab="PC #",ylab="Proportion of Variation")
lines(1:11,pc.cumprop,lty=3)

#Use ggplot2 to plot the first few pc's
ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +  geom_point(aes(col=FRACTURE), size=1)+ geom_hline(yintercept = 0, colour = "gray65") +  geom_vline(xintercept = 0, colour = "gray65") +  ggtitle("PCA plot of Osteo Study")

ggplot(data = pc.scores, aes(x = PC1, y = PC3)) +  geom_point(aes(col=FRACTURE), size=1)+ geom_hline(yintercept = 0, colour = "gray65") +  geom_vline(xintercept = 0, colour = "gray65") +  ggtitle("PCA plot of Osteo Study")

ggplot(data = pc.scores, aes(x = PC2, y = PC3)) +  geom_point(aes(col=FRACTURE), size=1)+ geom_hline(yintercept = 0, colour = "gray65") +  geom_vline(xintercept = 0, colour = "gray65") +  ggtitle("PCA plot of Osteo Study")

```
##Clustering

```{r fig.width=12}
#Lets look at a heatmap using hierarchical clustering to see if the 
#response naturually clusters out using the predictors
  
#Transposting the predictor matrix and giving the response categories its
#row names.
datasetHM <- read.csv("C:/Users/carol/OneDrive/Documents/MSDS6372/Proj2/glow500.csv", sep=",", stringsAsFactors = TRUE, header=TRUE)
str(dataset)

# list rows of data that have missing values 
datasetHM[!complete.cases(datasetHM),]
# create new dataset without missing data 
datasetHM <- na.omit(datasetHM)
attach(datasetHM)
#remove FRACSCORE feature
drops <- c("SITE_ID", "PHY_ID","FRACSCORE")
datasetHM <- datasetHM[ , !(names(datasetHM) %in% drops)]

library(RColorBrewer)
x<-t(dat.train.x)
colnames(x)<-dat.train.y
pheatmap(x,annotation_col=data.frame(FRACTURE=dat.train.y),scale="row",legend=T,color=colorRampPalette(c("blue","white", "red"), space = "rgb")(100))

detach(datasetHM)

attach(dataset) 
#glmnet requires a matrix 
##logistic regression
dat.train.x <- as.matrix(dat.train.x)
library(glmnet)
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")

#Get training set predictions...We know they are biased but lets create ROC's.
#These are predicted probabilities from logistic model  exp(b)/(1+exp(b))
fit.pred <- predict(cvfit, newx = dat.train.x, type = "response")

#Compare the prediction to the real outcome
head(fit.pred)
head(dat.train.y)

#Create ROC curves
pred <- prediction(fit.pred[,1], dat.train.y)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

#Plot ROC
plot(roc.perf)
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))

```