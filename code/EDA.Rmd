---
title: "MSDS 6372 Project 2"
output:
  html_document:
    toc: yes
    keep_md: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r setup, message=FALSE, include=FALSE} 
# Function to Install and Load R Packages 
Install_And_Load <- function(Required_Packages)
{
    Remaining_Packages <- Required_Packages[!(Required_Packages %in% installed.packages()[,"Package"])];

    if(length(Remaining_Packages)) 
    {
        install.packages(Remaining_Packages,repos = "http://cran.us.r-project.org");
    }
    for(package_name in Required_Packages)
    {
        library(package_name,character.only=TRUE,quietly=TRUE);
    }
}

# Specify the list of required packages to be installed and load    
Required_Packages=c("readxl",
"dplyr",
"plyr",
"glmnet",
"ISLR",
"leaps",
"ggplot2",
"ROCR",
"MASS",
"pheatmap",
"RColorBrewer",
"randomForest",
"gmodels",
"vcd",
"Amelia",
"e1071",
"corrplot",
"rpart",
"ROSE",
"caret",
"ResourceSelection",
"dummies",
"e1071",
"here"
);

# Call the Function
Install_And_Load(Required_Packages);
```
##Data Set 1: Osteoporosis in Women

From Hosmer, Lemeshow, and Sturdivant (2013), Applied Logistic Regression, 3rd Edition.
The Global Longitudinal Study of Osteoporosis in Women (GLOW) is an international study of osteoporosis in women aged 55 years and over. The major goals of the study are to examine prevention and treatment of fractures and distribution of risk factors among older women. Complete details on the study as well as a list of GLOW publications may be found at the Center for Outcomes Research web site, <http://www.outcomes-umassmed.org/glow>. 
There are over 60K observations in the original data set. This data set contains a sample of 500 of them. 
The link below is to a website with the data set and description of the variables. The data set in question is called "glow500".

<https://www.umass.edu/statdata/statdata/data/glow/index.html>
Note: If you choose this data set, you MAY NOT use the Hosmer, Lemeshow, and Sturdivant text to help you in your analysis.
You may only use Chapter 1 in order to obtain a description of the data.

Of course if you dont have the book

<https://www.umass.edu/statdata/statdata/data/glow/glow.pdf>
provides definitions to the variables.


The Global Longitudinal Study of Osteoporosis in Women (GLOW) (2005-2014) was a prospective cohort study of physician practices in the provision of prophylaxis and treatment against osteoporotic fractures. The goal of this research was to improve understanding of the risk and prevention of osteoporosis-related fractures among female residents of 10 countries who were 55 years of age and older. GLOW enrolled over 60,000 women through over 700 physicians in 10 countries, and conducted annual follow-up for up to 5 years through annual patient questionnaires.

#Setup: 
## Data Import and Cleaning
<p>Missing values were not detected in dataset. Special characters were removed from column headings.
<br>What we know/don't know about the sample (500): 
1. We do not know if the subjects are distributed equally around the world. We will assume that the same percentage from each region was selected for the sample in this dataset.
2. Based on the Sub_ID(Subject ID), we can assume that the datat is independent sample of participants.
3. 
</p>
```{r}
glow_data_file <- here("data", "glow500.csv")
dataset_loc <- 
dataset <- read.csv(glow_data_file, sep=",", stringsAsFactors = TRUE, header=TRUE,na.strings=c(""))

# List rows of data that have missing values 
Missing_values <- dataset[!complete.cases(dataset),]

# Create new dataset without missing data 
dataset <- na.omit(dataset)

#remove FRACSCORE feature per professor Turner
drops <- c("FRACSCORE")
dataset <- dataset[ , !(names(dataset) %in% drops)]

#Cleanup column names
colnames(dataset)[colnames(dataset)=="Ã¯..SUB_ID"] <- "SUB_ID"

#set categorical variables as factors
dataset$PRIORFRAC <- factor(dataset$PRIORFRAC,labels=c("0","1"))
dataset$PREMENO <- factor(dataset$PREMENO,labels=c("0","1"))
dataset$MOMFRAC <- factor(dataset$MOMFRAC,labels=c("0","1"))
dataset$ARMASSIST <- factor(dataset$ARMASSIST,labels=c("0","1"))
dataset$SMOKE <- factor(dataset$SMOKE,labels=c("0","1"))
dataset$RATERISK <- factor(dataset$RATERISK,labels=c("1","2","3"))
dataset$FRACTURE <- factor(dataset$FRACTURE,labels=c("0","1"))

str(dataset)
```
#  Exploratory Data Analysis
<br>
## Grouping Variables as Continuous, Categorical, and ID
<br>
```{r}
numericVar <- dataset[,5:8]
ID_var <- dataset[,c(1:3)]
set_noID <- dataset[4:14]
categoricalVar <- set_noID[,-c(2:5)]
```
##Create Train and Validation Datasets
<br>
```{r}
validation_index = createDataPartition(dataset$FRACTURE, p=0.70, list=FALSE)
validationData = dataset[-validation_index,c(4:14)]
trainingData = dataset[validation_index,c(4:14)]
```
##Summary Statistics
<p>Assumptions
This is a prospective study which means its a study over time of a group of similar individuals who differ with respect to certain factors under a study and how these factors affect rates of a certain outcome (Fracture vs No-Fracture)
Linearity - 
Independence of errors - Based on SUB_ID(Subject ID) we confirm each record is an independent sample.
Multicollinearity - Weight and BMI are highly correlated but we will remove one from the 
<br>
```{r}
#Summary stats by groups for continous predictors
t(aggregate(AGE~FRACTURE,data=dataset,summary))
t(aggregate(BMI~FRACTURE,data=dataset,summary))
t(aggregate(WEIGHT~FRACTURE,data=dataset,summary))
t(aggregate(HEIGHT~FRACTURE,data=dataset,summary))

#create an nicer summary table
index<-which(sapply(dataset,is.numeric))
tab.cont<-c()
for (i in index){
  tab.cont<-rbind(tab.cont,summary(dataset[,i]))
}
rownames(tab.cont)<-names(dataset)[index]
View(tab.cont)
tab.cont

# display the first 20 rows
print(head(dataset, n=20))

# display the dimensions of the dataset
print(dim(dataset))

# list types for each attribute
print(sapply(dataset,class))

# Standard Deviations for the non-categorical columns
std=sapply(set_noID,sd) 
print('The standard deviations are:')
print(std)
```
### Skewness
The further the distribution of the skew value from zero, 
the larger the skew to the left (negative skew value) or right (positive skew value). The skewness results of the continous variables show that Age, Weight, Height and BMI are positivly skewed.
```{r}
skew=apply(numericVar, 2, skewness) 
print(skew)
plot(skew)
```
###Correlations
<p>BMI and Weight show to be highly correlation which makes sense since weight is a factor in calculation of BMI. We will remove Weight from models in order to meet assumptions.</p>
<br>
```{r}
#Training dataset without ID columns
corrplot(cor(trainingData[2:5]), method = "number", type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45, main="Correlation - Training Dataset")
```
### Visualization of Continuous Variables
For the categorical variables, we show an unbalanced dataset of subjects with majority false PRIORFRAC, PREMENO, MOMFRAC, ARMASSIST, and SMOKE. There was a good balance of subjects in the 3 levels of RATERISK. An unblanced dataset will cause a model to favor the skewed numbers.

For the continous variables, we can see that BMI and Weight are highly correlated and weight and height are also correlated. When building the model, we will remove Weight as to meet the assumptions of logistic regression.
<br>
```{r}
# Data visualizations
dataset_numeric = numericVar
#Histograms
par(mfrow=c(2,2)) # put four figures in a row (2*4)
for (i in 1:4) {
  hist(dataset_numeric[,i],xlab=names(dataset_numeric)[i],main=names(dataset_numeric)[i])
}

#Density Plots
par(mfrow=c(2,2))
for(i in 1:4) {
  plot(density(dataset_numeric[,i]), xlab=names(dataset_numeric)[i], main=names(dataset_numeric)[i])
}

#Box And Whisker Plots
par(mfrow=c(2,2))
for(i in 1:4) {
  boxplot(dataset_numeric[,i], xlab=names(dataset_numeric)[i], main=names(dataset_numeric)[i])
}

#Barplots, which is used to count the accurances for categorical attributes 
dataset_categorical = set_noID[,-c(2:5)]
par(mfrow=c(3,2))
for(i in 1:6) {
  counts <- table(dataset_categorical[,i]) # get the count for each categorical value
  name <- names(dataset_categorical)[i]
  barplot(counts, main=name,col=c("lightblue","darkred"))
}

#Multivariate Visualization 
correlations1=cor(dataset_numeric)
print(correlations1)
par(mfrow=c(1,1))
corrplot(correlations1, methods="circle")

# pair-wise scatterplots of the numeric attributes
par(mfrow=c(1,1))
pairs(dataset_numeric)

#Scatterplot Matrix By Class (use different color to distinguish different class)
par(mfrow=c(1,1))
pairs(dataset_numeric, col=dataset[,5])

# density plots for each attribute by class value
X <- set_noID[2:5]
Y <- set_noID$FRACTURE
scales <- list(x=list(relation="free"), y=list(relation="free"))
par(mfrow=c(1,1))
featurePlot(x=set_noID[2:5], y=set_noID$FRACTURE, plot="density", scales=scales)
#Box And Whisker Plots By Class
par(mfrow=c(1,1))
featurePlot(x=set_noID[2:5], y=set_noID$FRACTURE, plot="box")
```
<br>
## Checking the Balance of the Full dataset
<p>The current sample dataset containes a larger propotion of subjects that did not develop fracture. Building a model against this dataset could produce bias towards the majority class. 
Below you will see how many subjects with(1)/without(0) Fractures as well as the proportion percentage for each. After splitting the dataset into training and validation(test) sets, we noticed the proportion of the training and test was not any better.
<p>We fit a logistic model on the unbalanced training dataset with a threshold of .05. It shows a Precision of 1 which says there are no false positives. Recall equals 0.20 is low and indicates that we have higher number of false negatives. The F equals 0.20 is also low and suggests weak accuracy of this model.
<p>We also plotted a ROC curve to visualize the model. The AUC equals 0.764 which is low and shows the data is not balanced.
<p>We will attempt to balance the dataset in order to create a more balanced distribution of and  a better prediction.<br>
```{r}

table(dataset$FRACTURE) 
prop.table(table(dataset$FRACTURE))

# split the data into training and validation sets
set.seed(84)
validation_index = createDataPartition(dataset$FRACTURE, p=0.75, list=FALSE)
validationData = dataset[-validation_index,c(4:14)]
trainingData = dataset[validation_index,c(4:14)]
prop.table(table(validationData$FRACTURE))
prop.table(table(trainingData$FRACTURE))

#fit a logistic regressio to unblanced training set
fit.dataset <- glm(formula=FRACTURE~ ., data = trainingData, family="binomial")
pred.fit.dataset <- predict(fit.dataset, newdata = validationData, type="response")
#Check Accuracy of fitted model.
accuracy.meas(validationData$FRACTURE,pred.fit.dataset, threshold=.05)

#Check Accuracy of Test dataset using ROC curve
roc.curve(validationData$FRACTURE, pred.fit.dataset, plotit = TRUE)
```
<br>
##Create a vector of all categorical variables and run frequency 2X2s with Mosaic plots.
<p>Chi-Square Test
<br>For the 2-way tables the chisq test independence will show if 2 categorical variables are related in some population. 
<br>Null Hypothesis: The two categorical variables are independent.
<br>Alternative Hypothesis: The two categorical variables are dependent

<br>Variable: PRIORFRAC
41% of subjects with Prior Franctures also had current Fractures but only make up 25% of the overall subjects in the sample that had prior fractures. The Chi-squared p-value favors overwhemingly the alternative hypothesis that the PRIORFRAC variable is dependent on Fracture variable.

<br>Variable: PREMENO
80% of the sample subjects are not in Pre-Menopausehad of which 24% had fractures. The same frequency of 25% Premenopausal women had fractures. The Chi-squared p-value favors the null hypothesis that the PREMENO variable is independent on Fracture variable.

<br>Variable: MOMFRAC
13% of subjects have Mothers with a history of fractures. Out of those 13%, 36% of subjects also had fractures. The Chi-squared p-value favors the alternative hypothesis that the MOMFRAC variable is probably dependent on Fracture variable.

<br>Variable: ARMASSIST
62% (312/500) subjects do not have Armassist of which 20% had fractures. Of those with Armassist, 33% had fractures. The Chi-squared p-value favors the alternative hypothesis that the ARMASSIST variable is most likely dependent on Fracture variable.

<br>Variable: SMOKE
In the dataset, 93% of subjects are non-smokers of which 26% had fractures. 7% of the subjects who were smokers of which 26% had no fractures. Although the subjects are not balance in smoker vs non-smoker category, the p-value for Chi-squared test shows .47 we favor the alternative hypothesis that the Smoke variable is dependent on the Fracture. 

<br>Variable: RATERISK 
Raterisk shows the frequency of subjects in each Raterisk level is between 29%-33%. This is pretty even in terms of how many subjects are within each Raterisk. For those that did have Fractures, their probability of a fracture increased with the level of Raterisk. This makes sense. </p>
```{r}
categoricalVarVec  <- c("PRIORFRAC","PREMENO","MOMFRAC","ARMASSIST","SMOKE","RATERISK")
for(categoricalVar in categoricalVarVec){ 
  CrossTable(dataset[,categoricalVar], dataset$FRACTURE, chisq = TRUE , expected = TRUE, dnn=c(categoricalVar,"FRACTURE")) 
  mosaicplot(CrossTable(dataset[ ,categoricalVar], dataset$FRACTURE)$t, main=paste("FRACTURE vs",categoricalVar, sep=" "), xlab=categoricalVar, ylab= "FRACTURE", color=T)
}
```
<br>
#Logistic Regression
<p>Training set will be 70% of dataset and Test set will be remaining 30%</p>
##Build Model using Training Data
<p>Question of Interest?
What are the odds of getting a fracture, given certain conditions?</p> 
```{r}
set.seed(84)
model <- glm(FRACTURE ~ AGE + WEIGHT + HEIGHT + BMI + PRIORFRAC + PREMENO + MOMFRAC + ARMASSIST + SMOKE + RATERISK,data=trainingData, family = "binomial" )
model
summary(model)

h1 <- hoslem.test(model$y, fitted(model), g = 10) #number of groups to divide dataset into is 10
h1
```
<p>Interpretation of logistic regression model:
Weight, height, BMI, Premeno, Armassist, and Smoke are not statistically significant variables. Priorfrac and Age are statistically significant variables and have the lowest p-value indicating a strong association with having a Fracture.
<br>
###PCA and Scree Plot
```{r}
new_my_data <- lapply(trainingData, function(x) {
  if(is.factor(x)) as.numeric(as.character(x)) else x
})
new_my_data <- data.frame(new_my_data)
str(new_my_data)


#Get Training Set
dat.train <- new_my_data

dat.train.x <- dat.train[,1:ncol(dat.train)]
dat.train.y <- dat.train$FRACTURE

dat.train.y <- as.factor(as.character(dat.train.y))

#PCA
pc.result<-prcomp(dat.train.x,scale=TRUE)
pc.scores<-pc.result$x
pc.scores<-data.frame(pc.scores)
pc.scores$FRACTURE <- dat.train.y

#or
#principal component analysis
prin_comp <- prcomp(new_my_data, scale. = T)
names(prin_comp)
prin_comp

#1. center and scale refers to respective mean and standard deviation of the variables that are used for normalization prior to implementing PCA

#outputs the mean of variables
prin_comp$center

#outputs the standard deviation of variables
prin_comp$scale

#2. The rotation measure provides the principal component loading. Each column of rotation matrix contains the principal component loading vector. This is the most important measure we should be interested in.

prin_comp$rotation
prin_comp$rotation[1:5,1:4]

dim(prin_comp$x)

#3 Plot result
biplot(prin_comp, scale = 0)

#4. The prcomp() function also provides the facility to compute standard deviation of each principal component. sdev refers to the standard deviation of principal components.

#compute standard deviation of each principal component
std_dev <- prin_comp$sdev

#compute variance
pr_var <- std_dev^2

#check variance of first 10 components
pr_var[1:10]

#We aim to find the components which explain the maximum variance. This is because, we want to retain as much information as possible using these components. So, higher is the explained variance, higher will be the information contained in those components.

#To compute the proportion of variance explained by each component, we simply divide the variance by sum of total variance. This results in:

#proportion of variance explained
prop_varex <- pr_var/sum(pr_var)
prop_varex[1:11]

#This shows that first principal component explains 10.3% variance. Second component explains 7.3% variance. Third component explains 6.2% variance and so on. So, how do we decide how many components should we select for modeling stage ?

#The answer to this question is provided by a scree plot. A scree plot is used to access components or factors which explains the most of variability in the data. It represents values in descending order.

#scree plot
plot(prop_varex, xlab = "Principal Component",
             ylab = "Proportion of Variance Explained",
             type = "b")

#The plot above shows that ~ all 11 components explains around 99% variance in the data set. In order words, using PCA did not help explaine variance. This is the power of PCA

#cumulative scree plot
plot(cumsum(prop_varex), xlab = "Principal Component",
              ylab = "Cumulative Proportion of Variance Explained",
              type = "b")
```
##Clustering

```{r fig.width=12}
#Lets look at a heatmap using hierarchical clustering to see if the 
#response naturually clusters out using the predictors
  
#Transposting the predictor matrix and giving the response categories its
#row names.
#Get Training Set
dat.train <- new_my_data

dat.train.x <- dat.train[,1:ncol(dat.train)]
dat.train.y <- dat.train$FRACTURE

dat.train.y <- as.factor(as.character(dat.train.y))

#Heatmap
x<-t(dat.train.x)
colnames(x)<-dat.train.y
pheatmap(x,annotation_col=data.frame(FRACTURE=dat.train.y),scale="row",legend=T,color=colorRampPalette(c("blue","white", "red"), space = "rgb")(100))

##logistic regression
dat.train.x <- as.matrix(dat.train.x)

cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")
```
##Creating a balanced dataset by Oversampling and check accuracy.
<p>Below we created a balanced dataset using ROSE package. The idea is that by creating an over sampled dataset with randomly duplicated records, we prodcued a more balanced dataset of subjects.
```{r}
#Look at the proporation of subjecs with Fractures from the Full dataset.
table(set_noID$FRACTURE)
prop.table(table(set_noID$FRACTURE))

#Create an oversampled dataset from Training dataset
over <- ovun.sample(FRACTURE~.,data=trainingData,method="over", N=564)$data
table(over$FRACTURE)

prop.table(table(over$FRACTURE))

#fit a logistic regressio to unblanced training set
fit.dataset <- glm(formula=FRACTURE~ ., data = over, family="binomial")
pred.fit.dataset <- predict(fit.dataset, newdata = over, type="response")
#Check Accuracy of fitted model.
accuracy.meas(over$FRACTURE,pred.fit.dataset, threshold=.05)

#Check Accuracy of Test dataset using ROC curve
roc.curve(over$FRACTURE, pred.fit.dataset, plotit = TRUE)
```